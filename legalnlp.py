import docx
from docx import Document
import spacy
from spacy import displacy
from io import BytesIO
from blackstone.pipeline.abbreviations import AbbreviationDetector
from blackstone.pipeline.sentence_segmenter import SentenceSegmenter
from blackstone.rules import CITATION_PATTERNS
from blackstone.utils.legislation_linker import extract_legislation_relations

from blackstone.displacy_palette import ner_displacy_options


def getText(filename):
    doc = docx.Document(filename)
    fullText = []
    for para in doc.paragraphs:
        fullText.append(para.text)
    return '\n'.join(fullText)


def get_top_cat(doc):
    """
    Function to identify the highest scoring category
    prediction generated by the text categoriser. 
    """
    cats = doc.cats
    max_score = max(cats.values())
    max_cats = [k for k, v in cats.items() if v == max_score]
    max_cat = max_cats[0]
    return (max_cat, max_score)


def main(filename):
    if filename == '':
        return [{'Please enter a filename': ''}]
    results = [{}]
    # Load the model
    nlp = spacy.load("en_blackstone_proto")
    sentence_segmenter = SentenceSegmenter(nlp.vocab, CITATION_PATTERNS)
    nlp.add_pipe(sentence_segmenter, before="parser")

    text = getText(filename)

    # Apply the model to the text
    doc = nlp(text)
    relations = extract_legislation_relations(doc)
    # Iterate through the entities identified by the model

    for provision, provision_url, instrument, instrument_url in relations:
        if(provision_url != 'None' and instrument_url != 'None' and provision != 'None' and instrument != 'None'):

            results.append({
                'Provision': provision,
                'Provision_url': provision_url,
                'Instrument': instrument,
                'Instrument_url': instrument_url
            })

    for ent in doc.ents:
        if ent.text != '' and ent.text != 'None':
            results.append({ent.label_: ent.text})
        #print(ent.text, ent.label_)

    # Call displacy and pass `ner_displacy_options` into the option parameter`
    # doc.user_data["title"] = "This is a visualization of the recognized Named Entities in the document"
    # displacy.serve(doc, style="ent", options=ner_displacy_options)

    # Get the sentences in the passage of text
    sentences = [sent.text for sent in doc.sents]

    # Print the sentence and the corresponding predicted category.
    for sentence in sentences:
        doc2 = nlp(sentence)
        top_category = get_top_cat(doc2)
        if top_category[0] != 'UNCAT':
            results.append({top_category[0]: sentence})
            #print(sentence, top_category[0])
        #print(f"\"{sentence}\" {top_category}\n")

    # Add the abbreviation pipe to the spacy pipeline.
    abbreviation_pipe = AbbreviationDetector(nlp)
    nlp.add_pipe(abbreviation_pipe)

    #doc = nlp('The European Court of Human Rights ("ECtHR") is the court ultimately responsible for applying the European Convention on Human Rights ("ECHR").')

    print("Abbreviation", "\t", "Definition")
    for abrv in doc._.abbreviations:
        results.append({"Abbreviations:": (
            f"{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}")})
        #print(f"{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}")
    return results
